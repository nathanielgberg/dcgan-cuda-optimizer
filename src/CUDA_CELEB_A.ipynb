{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "av4sMS0uOIER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7bb20d5-9d82-443d-e97e-b6707e4ec291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True\n",
        "print(torch.cuda.get_device_name(0))  # Check GPU type"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_kernels.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <math_constants.h>\n",
        "\n",
        "__global__ void double_elements_kernel(float* input, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        input[idx] = input[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void double_elements_backward_kernel(float* grad_output, float* grad_input, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        grad_input[idx] = grad_output[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_double_elements(float* input, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        double_elements_kernel<<<gridSize, blockSize>>>(input, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    void launch_double_elements_backward(float* grad_output, float* grad_input, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        double_elements_backward_kernel<<<gridSize, blockSize>>>(grad_output, grad_input, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv_transpose_general_kernel(const float* input, const float* weight, float* output,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in,\n",
        "    int H_out, int W_out,\n",
        "    int kH, int kW,\n",
        "    int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = batch * out_channels * H_out * W_out;\n",
        "    if (idx < total) {\n",
        "        // Decode the output index into (n, oc, y, x)\n",
        "        int temp = idx;\n",
        "        int x = temp % W_out;\n",
        "        temp /= W_out;\n",
        "        int y = temp % H_out;\n",
        "        temp /= H_out;\n",
        "        int oc = temp % out_channels;\n",
        "        int n = temp / out_channels;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int ic = 0; ic < in_channels; ic++) {\n",
        "            for (int ky = 0; ky < kH; ky++) {\n",
        "                for (int kx = 0; kx < kW; kx++) {\n",
        "                    int i_y = y + padding - ky;\n",
        "                    int i_x = x + padding - kx;\n",
        "                    if (i_y % stride == 0 && i_x % stride == 0) {\n",
        "                        i_y /= stride;\n",
        "                        i_x /= stride;\n",
        "                        if (i_y >= 0 && i_y < H_in && i_x >= 0 && i_x < W_in) {\n",
        "                            int input_idx = ((n * in_channels + ic) * H_in + i_y) * W_in + i_x;\n",
        "                            int flipped_ky = kH - 1 - ky;\n",
        "                            int flipped_kx = kW - 1 - kx;\n",
        "                            int weight_idx = ((ic * out_channels + oc) * kH + flipped_ky) * kW + flipped_kx;\n",
        "                            sum += input[input_idx] * weight[weight_idx];\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_conv_transpose_general(const float* input, const float* weight, float* output,\n",
        "        int batch, int in_channels, int out_channels,\n",
        "        int H_in, int W_in,\n",
        "        int H_out, int W_out,\n",
        "        int kH, int kW,\n",
        "        int stride, int padding) {\n",
        "\n",
        "        int total = batch * out_channels * H_out * W_out;\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (total + blockSize - 1) / blockSize;\n",
        "        conv_transpose_general_kernel<<<gridSize, blockSize>>>(input, weight, output,\n",
        "            batch, in_channels, out_channels,\n",
        "            H_in, W_in,\n",
        "            H_out, W_out,\n",
        "            kH, kW,\n",
        "            stride, padding);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void batchnorm_compute_mean_var(const float* input, float* mean, float* var, int N, int C, int H, int W) {\n",
        "    int c = blockIdx.x; // one block per channel\n",
        "    int channel_size = N * H * W;\n",
        "    __shared__ float shared_sum[256];\n",
        "    float sum = 0.0f;\n",
        "    for (int i = threadIdx.x; i < channel_size; i += blockDim.x) {\n",
        "        int n = i / (H * W);\n",
        "        int rem = i % (H * W);\n",
        "        int h = rem / W;\n",
        "        int w = rem % W;\n",
        "        int idx = ((n * C + c) * H + h) * W + w;\n",
        "        sum += input[idx];\n",
        "    }\n",
        "    shared_sum[threadIdx.x] = sum;\n",
        "    __syncthreads();\n",
        "    // Reduce within block.\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n",
        "        if (threadIdx.x < stride)\n",
        "            shared_sum[threadIdx.x] += shared_sum[threadIdx.x + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (threadIdx.x == 0)\n",
        "        mean[c] = shared_sum[0] / channel_size;\n",
        "    __syncthreads();\n",
        "\n",
        "    __shared__ float shared_sum2[256];\n",
        "    float sum_sq = 0.0f;\n",
        "    float m = mean[c];\n",
        "    for (int i = threadIdx.x; i < channel_size; i += blockDim.x) {\n",
        "        int n = i / (H * W);\n",
        "        int rem = i % (H * W);\n",
        "        int h = rem / W;\n",
        "        int w = rem % W;\n",
        "        int idx = ((n * C + c) * H + h) * W + w;\n",
        "        float diff = input[idx] - m;\n",
        "        sum_sq += diff * diff;\n",
        "    }\n",
        "    shared_sum2[threadIdx.x] = sum_sq;\n",
        "    __syncthreads();\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n",
        "        if (threadIdx.x < stride)\n",
        "            shared_sum2[threadIdx.x] += shared_sum2[threadIdx.x + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (threadIdx.x == 0)\n",
        "        var[c] = shared_sum2[0] / channel_size;\n",
        "}\n",
        "\n",
        "__global__ void batchnorm_apply(const float* input, float* output, const float* mean, const float* var,\n",
        "                                const float* gamma, const float* beta, int N, int C, int H, int W, float eps) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = N * C * H * W;\n",
        "    if (idx < total) {\n",
        "        int n = idx / (C * H * W);\n",
        "        int rem = idx % (C * H * W);\n",
        "        int c = rem / (H * W);\n",
        "        int r = rem % (H * W);\n",
        "        int h = r / W;\n",
        "        int w = r % W;\n",
        "        int index = ((n * C + c) * H + h) * W + w;\n",
        "        float m = mean[c];\n",
        "        float v = var[c];\n",
        "        float norm = (input[index] - m) / sqrtf(v + eps);\n",
        "        output[index] = gamma[c] * norm + beta[c];\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_batchnorm(const float* input, float* output, const float* gamma, const float* beta,\n",
        "                          int N, int C, int H, int W, float eps) {\n",
        "        int channel_size = N * H * W;\n",
        "        float *mean, *var;\n",
        "        size_t size = C * sizeof(float);\n",
        "        cudaMalloc(&mean, size);\n",
        "        cudaMalloc(&var, size);\n",
        "\n",
        "        int blockSize = 256;\n",
        "        int gridSize = C;  // one block per channel.\n",
        "        batchnorm_compute_mean_var<<<gridSize, blockSize>>>(input, mean, var, N, C, H, W);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        int total = N * C * H * W;\n",
        "        blockSize = 256;\n",
        "        gridSize = (total + blockSize - 1) / blockSize;\n",
        "        batchnorm_apply<<<gridSize, blockSize>>>(input, output, mean, var, gamma, beta, N, C, H, W, eps);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        cudaFree(mean);\n",
        "        cudaFree(var);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_kernel(const float* input, const float* weight, float* output,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in,\n",
        "    int H_out, int W_out,\n",
        "    int kH, int kW,\n",
        "    int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = batch * out_channels * H_out * W_out;\n",
        "    if (idx < total) {\n",
        "        // Decode index into (n, oc, y, x)\n",
        "        int temp = idx;\n",
        "        int x = temp % W_out; temp /= W_out;\n",
        "        int y = temp % H_out; temp /= H_out;\n",
        "        int oc = temp % out_channels; temp /= out_channels;\n",
        "        int n = temp;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        // For each input channel and kernel element:\n",
        "        for (int ic = 0; ic < in_channels; ic++) {\n",
        "            for (int ky = 0; ky < kH; ky++) {\n",
        "                for (int kx = 0; kx < kW; kx++) {\n",
        "                    int in_y = y * stride - padding + ky;\n",
        "                    int in_x = x * stride - padding + kx;\n",
        "                    if (in_y >= 0 && in_y < H_in && in_x >= 0 && in_x < W_in) {\n",
        "                        int input_idx = ((n * in_channels + ic) * H_in + in_y) * W_in + in_x;\n",
        "                        // Weight shape: (out_channels, in_channels, kH, kW)\n",
        "                        int weight_idx = ((oc * in_channels + ic) * kH + ky) * kW + kx;\n",
        "                        sum += input[input_idx] * weight[weight_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_conv2d(const float* input, const float* weight, float* output,\n",
        "         int batch, int in_channels, int out_channels,\n",
        "         int H_in, int W_in,\n",
        "         int H_out, int W_out,\n",
        "         int kH, int kW,\n",
        "         int stride, int padding) {\n",
        "         int total = batch * out_channels * H_out * W_out;\n",
        "         int blockSize = 256;\n",
        "         int gridSize = (total + blockSize - 1) / blockSize;\n",
        "         conv2d_kernel<<<gridSize, blockSize>>>(input, weight, output,\n",
        "             batch, in_channels, out_channels,\n",
        "             H_in, W_in,\n",
        "             H_out, W_out,\n",
        "             kH, kW,\n",
        "             stride, padding);\n",
        "         cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void relu_kernel(const float* input, float* output, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float x = input[idx];\n",
        "        output[idx] = (x > 0.0f) ? x : 0.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void relu_backward_kernel(const float* input, const float* grad_output, float* grad_input, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        grad_input[idx] = (input[idx] > 0.0f) ? grad_output[idx] : 0.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_relu(const float* input, float* output, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        relu_kernel<<<gridSize, blockSize>>>(input, output, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    void launch_relu_backward(const float* input, const float* grad_output, float* grad_input, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        relu_backward_kernel<<<gridSize, blockSize>>>(input, grad_output, grad_input, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv_transpose2d_backward_input_kernel(\n",
        "    const float* d_output, const float* weight, float* d_input,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in, int H_out, int W_out,\n",
        "    int kH, int kW, int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = batch * in_channels * H_in * W_in;\n",
        "    if (idx < total) {\n",
        "        int temp = idx;\n",
        "        int x = temp % W_in;\n",
        "        temp /= W_in;\n",
        "        int y = temp % H_in;\n",
        "        temp /= H_in;\n",
        "        int ic = temp % in_channels;\n",
        "        int n = temp / in_channels;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int oc = 0; oc < out_channels; oc++) {\n",
        "            for (int ky = 0; ky < kH; ky++) {\n",
        "                for (int kx = 0; kx < kW; kx++) {\n",
        "                    int o_y = y * stride - padding + ky;\n",
        "                    int o_x = x * stride - padding + kx;\n",
        "                    if (o_y >= 0 && o_y < H_out && o_x >= 0 && o_x < W_out) {\n",
        "                        int d_output_idx = ((n * out_channels + oc) * H_out + o_y) * W_out + o_x;\n",
        "                        int weight_idx = ((ic * out_channels + oc) * kH + ky) * kW + kx;\n",
        "                        sum += d_output[d_output_idx] * weight[weight_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        d_input[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv_transpose2d_backward_weight_kernel(\n",
        "    const float* input, const float* d_output, float* d_weight,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in, int H_out, int W_out,\n",
        "    int kH, int kW, int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = in_channels * out_channels * kH * kW;\n",
        "    if (idx < total) {\n",
        "        int temp = idx;\n",
        "        int kx = temp % kW;\n",
        "        temp /= kW;\n",
        "        int ky = temp % kH;\n",
        "        temp /= kH;\n",
        "        int oc = temp % out_channels;\n",
        "        int ic = temp / out_channels;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int n = 0; n < batch; n++) {\n",
        "            for (int y = 0; y < H_out; y++) {\n",
        "                for (int x = 0; x < W_out; x++) {\n",
        "                    int i_y = y * stride - padding + ky;\n",
        "                    int i_x = x * stride - padding + kx;\n",
        "                    if (i_y >= 0 && i_y < H_in && i_x >= 0 && i_x < W_in) {\n",
        "                        int input_idx = ((n * in_channels + ic) * H_in + i_y) * W_in + i_x;\n",
        "                        int d_output_idx = ((n * out_channels + oc) * H_out + y) * W_out + x;\n",
        "                        sum += input[input_idx] * d_output[d_output_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        d_weight[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_conv_transpose2d_backward(\n",
        "        const float* d_output, const float* input, const float* weight,\n",
        "        float* d_input, float* d_weight,\n",
        "        int batch, int in_channels, int out_channels,\n",
        "        int H_in, int W_in, int H_out, int W_out,\n",
        "        int kH, int kW, int stride, int padding) {\n",
        "\n",
        "        int total_input = batch * in_channels * H_in * W_in;\n",
        "        int total_weight = in_channels * out_channels * kH * kW;\n",
        "\n",
        "        int blockSize = 256;\n",
        "        int gridSize_input = (total_input + blockSize - 1) / blockSize;\n",
        "        int gridSize_weight = (total_weight + blockSize - 1) / blockSize;\n",
        "\n",
        "        conv_transpose2d_backward_input_kernel<<<gridSize_input, blockSize>>>(\n",
        "            d_output, weight, d_input, batch, in_channels, out_channels,\n",
        "            H_in, W_in, H_out, W_out, kH, kW, stride, padding);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        conv_transpose2d_backward_weight_kernel<<<gridSize_weight, blockSize>>>(\n",
        "            input, d_output, d_weight, batch, in_channels, out_channels,\n",
        "            H_in, W_in, H_out, W_out, kH, kW, stride, padding);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward_input_kernel(\n",
        "    const float* d_output, const float* weight, float* d_input,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in, int H_out, int W_out,\n",
        "    int kH, int kW, int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = batch * in_channels * H_in * W_in;\n",
        "    if (idx < total) {\n",
        "        int temp = idx;\n",
        "        int x = temp % W_in;\n",
        "        temp /= W_in;\n",
        "        int y = temp % H_in;\n",
        "        temp /= H_in;\n",
        "        int ic = temp % in_channels;\n",
        "        int n = temp / in_channels;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int oc = 0; oc < out_channels; oc++) {\n",
        "            for (int ky = 0; ky < kH; ky++) {\n",
        "                for (int kx = 0; kx < kW; kx++) {\n",
        "                    int o_y = (y + padding - ky) / stride;\n",
        "                    int o_x = (x + padding - kx) / stride;\n",
        "                    if ((y + padding - ky) % stride == 0 && (x + padding - kx) % stride == 0 &&\n",
        "                        o_y >= 0 && o_y < H_out && o_x >= 0 && o_x < W_out) {\n",
        "                        int d_output_idx = ((n * out_channels + oc) * H_out + o_y) * W_out + o_x;\n",
        "                        int weight_idx = ((oc * in_channels + ic) * kH + ky) * kW + kx;\n",
        "                        sum += d_output[d_output_idx] * weight[weight_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        d_input[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward_weight_kernel(\n",
        "    const float* input, const float* d_output, float* d_weight,\n",
        "    int batch, int in_channels, int out_channels,\n",
        "    int H_in, int W_in, int H_out, int W_out,\n",
        "    int kH, int kW, int stride, int padding) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total = out_channels * in_channels * kH * kW;\n",
        "    if (idx < total) {\n",
        "        int temp = idx;\n",
        "        int kx = temp % kW;\n",
        "        temp /= kW;\n",
        "        int ky = temp % kH;\n",
        "        temp /= kH;\n",
        "        int ic = temp % in_channels;\n",
        "        int oc = temp / in_channels;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int n = 0; n < batch; n++) {\n",
        "            for (int y = 0; y < H_out; y++) {\n",
        "                for (int x = 0; x < W_out; x++) {\n",
        "                    int i_y = y * stride - padding + ky;\n",
        "                    int i_x = x * stride - padding + kx;\n",
        "                    if (i_y >= 0 && i_y < H_in && i_x >= 0 && i_x < W_in) {\n",
        "                        int input_idx = ((n * in_channels + ic) * H_in + i_y) * W_in + i_x;\n",
        "                        int d_output_idx = ((n * out_channels + oc) * H_out + y) * W_out + x;\n",
        "                        sum += input[input_idx] * d_output[d_output_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        d_weight[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_conv2d_backward(\n",
        "        const float* d_output, const float* input, const float* weight,\n",
        "        float* d_input, float* d_weight,\n",
        "        int batch, int in_channels, int out_channels,\n",
        "        int H_in, int W_in, int H_out, int W_out,\n",
        "        int kH, int kW, int stride, int padding) {\n",
        "\n",
        "        int total_input = batch * in_channels * H_in * W_in;\n",
        "        int total_weight = out_channels * in_channels * kH * kW;\n",
        "\n",
        "        int blockSize = 256;\n",
        "        int gridSize_input = (total_input + blockSize - 1) / blockSize;\n",
        "        int gridSize_weight = (total_weight + blockSize - 1) / blockSize;\n",
        "\n",
        "        conv2d_backward_input_kernel<<<gridSize_input, blockSize>>>(\n",
        "            d_output, weight, d_input, batch, in_channels, out_channels,\n",
        "            H_in, W_in, H_out, W_out, kH, kW, stride, padding);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        conv2d_backward_weight_kernel<<<gridSize_weight, blockSize>>>(\n",
        "            input, d_output, d_weight, batch, in_channels, out_channels,\n",
        "            H_in, W_in, H_out, W_out, kH, kW, stride, padding);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void batchnorm2d_backward_kernel(\n",
        "    const float* grad_output, const float* input, const float* mean, const float* var,\n",
        "    const float* gamma, float* d_input, float* d_gamma, float* d_beta,\n",
        "    int N, int C, int H, int W, float eps) {\n",
        "\n",
        "    int c = blockIdx.x;\n",
        "    int channel_size = N * H * W;\n",
        "\n",
        "    __shared__ float shared_dgamma[256];\n",
        "    __shared__ float shared_dbeta[256];\n",
        "\n",
        "    float dgamma = 0.0f;\n",
        "    float dbeta = 0.0f;\n",
        "    float inv_std = rsqrtf(var[c] + eps);\n",
        "\n",
        "    for (int i = threadIdx.x; i < channel_size; i += blockDim.x) {\n",
        "        int n = i / (H * W);\n",
        "        int rem = i % (H * W);\n",
        "        int h = rem / W;\n",
        "        int w = rem % W;\n",
        "        int idx = ((n * C + c) * H + h) * W + w;\n",
        "        float x_hat = (input[idx] - mean[c]) * inv_std;\n",
        "        dgamma += grad_output[idx] * x_hat;\n",
        "        dbeta += grad_output[idx];\n",
        "    }\n",
        "\n",
        "    shared_dgamma[threadIdx.x] = dgamma;\n",
        "    shared_dbeta[threadIdx.x] = dbeta;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n",
        "        if (threadIdx.x < stride) {\n",
        "            shared_dgamma[threadIdx.x] += shared_dgamma[threadIdx.x + stride];\n",
        "            shared_dbeta[threadIdx.x] += shared_dbeta[threadIdx.x + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        atomicAdd(&d_gamma[c], shared_dgamma[0]);\n",
        "        atomicAdd(&d_beta[c], shared_dbeta[0]);\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int i = threadIdx.x; i < channel_size; i += blockDim.x) {\n",
        "        int n = i / (H * W);\n",
        "        int rem = i % (H * W);\n",
        "        int h = rem / W;\n",
        "        int w = rem % W;\n",
        "        int idx = ((n * C + c) * H + h) * W + w;\n",
        "\n",
        "        float x_hat = (input[idx] - mean[c]) * inv_std;\n",
        "        float d_input_val = (grad_output[idx] - dbeta / channel_size - x_hat * dgamma / channel_size) * gamma[c] * inv_std;\n",
        "        d_input[idx] = d_input_val;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_batchnorm2d_backward(\n",
        "        const float* grad_output, const float* input, const float* mean, const float* var,\n",
        "        const float* gamma, float* d_input, float* d_gamma, float* d_beta,\n",
        "        int N, int C, int H, int W, float eps) {\n",
        "\n",
        "        int blockSize = 256;\n",
        "        int gridSize = C;\n",
        "\n",
        "        batchnorm2d_backward_kernel<<<gridSize, blockSize>>>(\n",
        "            grad_output, input, mean, var, gamma, d_input, d_gamma, d_beta,\n",
        "            N, C, H, W, eps);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void leaky_relu_kernel(const float* input, float* output, int n, float alpha) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float x = input[idx];\n",
        "        output[idx] = (x > 0.0f) ? x : alpha * x;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void leaky_relu_backward_kernel(const float* input, const float* grad_output, float* grad_input, int n, float alpha) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        grad_input[idx] = (input[idx] > 0.0f) ? grad_output[idx] : alpha * grad_output[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_leaky_relu(const float* input, float* output, int n, float alpha) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        leaky_relu_kernel<<<gridSize, blockSize>>>(input, output, n, alpha);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    void launch_leaky_relu_backward(const float* input, const float* grad_output, float* grad_input, int n, float alpha) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        leaky_relu_backward_kernel<<<gridSize, blockSize>>>(\n",
        "            input, grad_output, grad_input, n, alpha\n",
        "        );\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sigmoid_kernel(const float* input, float* output, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        output[idx] = 1.0f / (1.0f + expf(-input[idx]));\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sigmoid_backward_kernel(const float* output, const float* grad_output, float* grad_input, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float sigmoid_val = output[idx];\n",
        "        grad_input[idx] = grad_output[idx] * sigmoid_val * (1.0f - sigmoid_val);\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_sigmoid(const float* input, float* output, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        sigmoid_kernel<<<gridSize, blockSize>>>(input, output, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    void launch_sigmoid_backward(const float* output, const float* grad_output, float* grad_input, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        sigmoid_backward_kernel<<<gridSize, blockSize>>>(output, grad_output, grad_input, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void tanh_kernel(const float* input, float* output, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        output[idx] = tanhf(input[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void tanh_backward_kernel(const float* output, const float* grad_output, float* grad_input, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float tanh_val = output[idx];\n",
        "        grad_input[idx] = grad_output[idx] * (1.0f - tanh_val * tanh_val);\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "    void launch_tanh(const float* input, float* output, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        tanh_kernel<<<gridSize, blockSize>>>(input, output, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    void launch_tanh_backward(const float* output, const float* grad_output, float* grad_input, int n) {\n",
        "        int blockSize = 256;\n",
        "        int gridSize = (n + blockSize - 1) / blockSize;\n",
        "        tanh_backward_kernel<<<gridSize, blockSize>>>(output, grad_output, grad_input, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1K0zFCGzRSq",
        "outputId": "381c27f9-fb73-4cb3-a948-26cf8a1fe003"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_kernels.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -shared -o cuda_kernels.so -Xcompiler -fPIC cuda_kernels.cu"
      ],
      "metadata": {
        "id": "YISRR-ULYYw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332b1d1b-ef50-42f0-838d-7f3484d182b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcuda_kernels.cu(168)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"channel_size\"\u001b[0m was declared but never referenced\n",
            "          int channel_size = N * H * W;\n",
            "              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh cuda_kernels.so"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utZ3ujnlZnQb",
        "outputId": "11763923-9a86-4ad2-e745-2b9462c7b811"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 1.1M Mar 16 22:09 cuda_kernels.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ctypes\n",
        "import torch\n",
        "\n",
        "cuda_lib = ctypes.cdll.LoadLibrary('./cuda_kernels.so')\n",
        "\n",
        "cuda_lib.launch_double_elements.argtypes = [ctypes.c_void_p, ctypes.c_int]\n",
        "\n",
        "def double_elements(tensor):\n",
        "    if not tensor.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not tensor.is_contiguous():\n",
        "        tensor = tensor.contiguous()\n",
        "    ptr = tensor.data_ptr()\n",
        "    n = tensor.numel()\n",
        "    cuda_lib.launch_double_elements(ctypes.c_void_p(ptr), ctypes.c_int(n))\n",
        "\n",
        "\n",
        "# Set argument types for the kernel launcher.\n",
        "cuda_lib.launch_conv_transpose_general.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int\n",
        "]\n",
        "\n",
        "cuda_lib.launch_double_elements_backward.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]\n",
        "\n",
        "def double_elements_backward(grad_output):\n",
        "    if not grad_output.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not grad_output.is_contiguous():\n",
        "        grad_output = grad_output.contiguous()\n",
        "\n",
        "    grad_input = torch.empty_like(grad_output)\n",
        "\n",
        "    cuda_lib.launch_double_elements_backward(\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_input.data_ptr()),\n",
        "        ctypes.c_int(grad_output.numel())\n",
        "    )\n",
        "\n",
        "    return grad_input\n",
        "\n",
        "\n",
        "def conv_transpose_general_forward(input, weight, stride, padding):\n",
        "    input = input.contiguous()\n",
        "    weight = weight.contiguous()\n",
        "    batch, in_channels, H_in, W_in = input.shape\n",
        "    _, out_channels, kH, kW = weight.shape\n",
        "    H_out = (H_in - 1) * stride - 2 * padding + kH\n",
        "    W_out = (W_in - 1) * stride - 2 * padding + kW\n",
        "    output_shape = (batch, out_channels, H_out, W_out)\n",
        "    output = torch.empty(output_shape, device=input.device, dtype=input.dtype)\n",
        "\n",
        "    cuda_lib.launch_conv_transpose_general(\n",
        "        ctypes.c_void_p(int(input.data_ptr())),\n",
        "        ctypes.c_void_p(int(weight.data_ptr())),\n",
        "        ctypes.c_void_p(int(output.data_ptr())),\n",
        "        ctypes.c_int(batch),\n",
        "        ctypes.c_int(in_channels),\n",
        "        ctypes.c_int(out_channels),\n",
        "        ctypes.c_int(H_in),\n",
        "        ctypes.c_int(W_in),\n",
        "        ctypes.c_int(H_out),\n",
        "        ctypes.c_int(W_out),\n",
        "        ctypes.c_int(kH),\n",
        "        ctypes.c_int(kW),\n",
        "        ctypes.c_int(stride),\n",
        "        ctypes.c_int(padding)\n",
        "    )\n",
        "    return output\n",
        "\n",
        "\n",
        "# Define the argument types for our batchnorm launcher.\n",
        "cuda_lib.launch_batchnorm.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_float\n",
        "]\n",
        "\n",
        "def batchnorm_forward(input, gamma, beta, eps, N, C, H, W):\n",
        "    input = input.contiguous()\n",
        "    output = torch.empty_like(input)\n",
        "    cuda_lib.launch_batchnorm(ctypes.c_void_p(int(input.data_ptr())),\n",
        "                                 ctypes.c_void_p(int(output.data_ptr())),\n",
        "                                 ctypes.c_void_p(int(gamma.data_ptr())),\n",
        "                                 ctypes.c_void_p(int(beta.data_ptr())),\n",
        "                                 ctypes.c_int(N),\n",
        "                                 ctypes.c_int(C),\n",
        "                                 ctypes.c_int(H),\n",
        "                                 ctypes.c_int(W),\n",
        "                                 ctypes.c_float(eps))\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_batchnorm2d_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_float\n",
        "]\n",
        "\n",
        "def batchnorm2d_backward(grad_output, input, mean, var, gamma, eps):\n",
        "    input = input.contiguous()\n",
        "    grad_output = grad_output.contiguous()\n",
        "    gamma = gamma.contiguous()\n",
        "    mean = mean.contiguous()\n",
        "    var = var.contiguous()\n",
        "\n",
        "    N, C, H, W = input.shape\n",
        "    d_input = torch.zeros_like(input)\n",
        "    d_gamma = torch.zeros_like(gamma)\n",
        "    d_beta = torch.zeros_like(gamma)\n",
        "\n",
        "    cuda_lib.launch_batchnorm2d_backward(\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(mean.data_ptr()),\n",
        "        ctypes.c_void_p(var.data_ptr()),\n",
        "        ctypes.c_void_p(gamma.data_ptr()),\n",
        "        ctypes.c_void_p(d_input.data_ptr()),\n",
        "        ctypes.c_void_p(d_gamma.data_ptr()),\n",
        "        ctypes.c_void_p(d_beta.data_ptr()),\n",
        "        ctypes.c_int(N), ctypes.c_int(C), ctypes.c_int(H), ctypes.c_int(W),\n",
        "        ctypes.c_float(eps)\n",
        "    )\n",
        "\n",
        "    return d_input, d_gamma, d_beta\n",
        "\n",
        "\n",
        "cuda_lib.launch_conv2d.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int\n",
        "]\n",
        "\n",
        "def conv2d_forward(input, weight, stride, padding):\n",
        "    input = input.contiguous()\n",
        "    weight = weight.contiguous()\n",
        "    batch, in_channels, H_in, W_in = input.shape\n",
        "    out_channels, _, kH, kW = weight.shape\n",
        "    H_out = (H_in + 2 * padding - kH) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kW) // stride + 1\n",
        "    output_shape = (batch, out_channels, H_out, W_out)\n",
        "    output = torch.empty(output_shape, device=input.device, dtype=input.dtype)\n",
        "    cuda_lib.launch_conv2d(\n",
        "        ctypes.c_void_p(int(input.data_ptr())),\n",
        "        ctypes.c_void_p(int(weight.data_ptr())),\n",
        "        ctypes.c_void_p(int(output.data_ptr())),\n",
        "        ctypes.c_int(batch),\n",
        "        ctypes.c_int(in_channels),\n",
        "        ctypes.c_int(out_channels),\n",
        "        ctypes.c_int(H_in),\n",
        "        ctypes.c_int(W_in),\n",
        "        ctypes.c_int(H_out),\n",
        "        ctypes.c_int(W_out),\n",
        "        ctypes.c_int(kH),\n",
        "        ctypes.c_int(kW),\n",
        "        ctypes.c_int(stride),\n",
        "        ctypes.c_int(padding)\n",
        "    )\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_conv_transpose2d_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int\n",
        "]\n",
        "\n",
        "def conv_transpose2d_backward(d_output, input, weight, stride, padding):\n",
        "    input = input.contiguous()\n",
        "    weight = weight.contiguous()\n",
        "    d_output = d_output.contiguous()\n",
        "\n",
        "    batch, in_channels, H_in, W_in = input.shape\n",
        "    _, out_channels, kH, kW = weight.shape\n",
        "    H_out = (H_in - 1) * stride - 2 * padding + kH\n",
        "    W_out = (W_in - 1) * stride - 2 * padding + kW\n",
        "\n",
        "    d_input = torch.zeros_like(input)\n",
        "    d_weight = torch.zeros_like(weight)\n",
        "\n",
        "    cuda_lib.launch_conv_transpose2d_backward(\n",
        "        ctypes.c_void_p(d_output.data_ptr()),\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(weight.data_ptr()),\n",
        "        ctypes.c_void_p(d_input.data_ptr()),\n",
        "        ctypes.c_void_p(d_weight.data_ptr()),\n",
        "        ctypes.c_int(batch), ctypes.c_int(in_channels), ctypes.c_int(out_channels),\n",
        "        ctypes.c_int(H_in), ctypes.c_int(W_in),\n",
        "        ctypes.c_int(H_out), ctypes.c_int(W_out),\n",
        "        ctypes.c_int(kH), ctypes.c_int(kW),\n",
        "        ctypes.c_int(stride), ctypes.c_int(padding)\n",
        "    )\n",
        "\n",
        "    return d_input, d_weight\n",
        "\n",
        "cuda_lib.launch_conv2d_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_void_p, ctypes.c_void_p,\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int,\n",
        "    ctypes.c_int, ctypes.c_int\n",
        "]\n",
        "\n",
        "def conv2d_backward(d_output, input, weight, stride, padding):\n",
        "    input = input.contiguous()\n",
        "    weight = weight.contiguous()\n",
        "    d_output = d_output.contiguous()\n",
        "\n",
        "    batch, in_channels, H_in, W_in = input.shape\n",
        "    out_channels, _, kH, kW = weight.shape\n",
        "    H_out = (H_in + 2 * padding - kH) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kW) // stride + 1\n",
        "\n",
        "    d_input = torch.zeros_like(input)\n",
        "    d_weight = torch.zeros_like(weight)\n",
        "\n",
        "    cuda_lib.launch_conv2d_backward(\n",
        "        ctypes.c_void_p(d_output.data_ptr()),\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(weight.data_ptr()),\n",
        "        ctypes.c_void_p(d_input.data_ptr()),\n",
        "        ctypes.c_void_p(d_weight.data_ptr()),\n",
        "        ctypes.c_int(batch), ctypes.c_int(in_channels), ctypes.c_int(out_channels),\n",
        "        ctypes.c_int(H_in), ctypes.c_int(W_in),\n",
        "        ctypes.c_int(H_out), ctypes.c_int(W_out),\n",
        "        ctypes.c_int(kH), ctypes.c_int(kW),\n",
        "        ctypes.c_int(stride), ctypes.c_int(padding)\n",
        "    )\n",
        "\n",
        "    return d_input, d_weight\n",
        "\n",
        "cuda_lib.launch_relu.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]\n",
        "\n",
        "def relu_forward(input):\n",
        "    if not input.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "    n = input.numel()\n",
        "    output = torch.empty_like(input)\n",
        "    cuda_lib.launch_relu(\n",
        "        ctypes.c_void_p(int(input.data_ptr())),\n",
        "        ctypes.c_void_p(int(output.data_ptr())),\n",
        "        ctypes.c_int(n)\n",
        "    )\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_relu_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int\n",
        "]\n",
        "\n",
        "def relu_backward(input, grad_output):\n",
        "    if not input.is_cuda or not grad_output.is_cuda:\n",
        "        raise ValueError(\"Tensors must be on CUDA\")\n",
        "\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "    if not grad_output.is_contiguous():\n",
        "        grad_output = grad_output.contiguous()\n",
        "\n",
        "    grad_input = torch.empty_like(grad_output)\n",
        "\n",
        "    cuda_lib.launch_relu_backward(\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_input.data_ptr()),\n",
        "        ctypes.c_int(input.numel())\n",
        "    )\n",
        "\n",
        "    return grad_input\n",
        "\n",
        "cuda_lib.launch_leaky_relu.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int, ctypes.c_float\n",
        "]\n",
        "\n",
        "def leaky_relu_forward(input, alpha=0.01):\n",
        "    if not input.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "\n",
        "    output = torch.empty_like(input)\n",
        "\n",
        "    cuda_lib.launch_leaky_relu(\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(output.data_ptr()),\n",
        "        ctypes.c_int(input.numel()),\n",
        "        ctypes.c_float(alpha)\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_leaky_relu_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int, ctypes.c_float\n",
        "]\n",
        "\n",
        "def leaky_relu_backward(input, grad_output, alpha=0.01):\n",
        "    if not input.is_cuda or not grad_output.is_cuda:\n",
        "        raise ValueError(\"Tensors must be on CUDA\")\n",
        "\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "    if not grad_output.is_contiguous():\n",
        "        grad_output = grad_output.contiguous()\n",
        "\n",
        "    grad_input = torch.empty_like(grad_output)\n",
        "\n",
        "    cuda_lib.launch_leaky_relu_backward(\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_input.data_ptr()),\n",
        "        ctypes.c_int(input.numel()),\n",
        "        ctypes.c_float(alpha)\n",
        "    )\n",
        "\n",
        "    return grad_input\n",
        "\n",
        "cuda_lib.launch_sigmoid.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int\n",
        "]\n",
        "\n",
        "def sigmoid_forward(input):\n",
        "    if not input.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "\n",
        "    output = torch.empty_like(input)\n",
        "\n",
        "    cuda_lib.launch_sigmoid(\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(output.data_ptr()),\n",
        "        ctypes.c_int(input.numel())\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_sigmoid_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int\n",
        "]\n",
        "\n",
        "def sigmoid_backward(output, grad_output):\n",
        "    if not output.is_cuda or not grad_output.is_cuda:\n",
        "        raise ValueError(\"Tensors must be on CUDA\")\n",
        "\n",
        "    if not output.is_contiguous():\n",
        "        output = output.contiguous()\n",
        "    if not grad_output.is_contiguous():\n",
        "        grad_output = grad_output.contiguous()\n",
        "\n",
        "    grad_input = torch.empty_like(grad_output)\n",
        "\n",
        "    cuda_lib.launch_sigmoid_backward(\n",
        "        ctypes.c_void_p(output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_input.data_ptr()),\n",
        "        ctypes.c_int(output.numel())\n",
        "    )\n",
        "\n",
        "    return grad_input\n",
        "\n",
        "cuda_lib.launch_tanh.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int\n",
        "]\n",
        "\n",
        "def tanh_forward(input):\n",
        "    if not input.is_cuda:\n",
        "        raise ValueError(\"Tensor must be on CUDA\")\n",
        "    if not input.is_contiguous():\n",
        "        input = input.contiguous()\n",
        "\n",
        "    output = torch.empty_like(input)\n",
        "\n",
        "    cuda_lib.launch_tanh(\n",
        "        ctypes.c_void_p(input.data_ptr()),\n",
        "        ctypes.c_void_p(output.data_ptr()),\n",
        "        ctypes.c_int(input.numel())\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "cuda_lib.launch_tanh_backward.argtypes = [\n",
        "    ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int\n",
        "]\n",
        "\n",
        "def tanh_backward(output, grad_output):\n",
        "    if not output.is_cuda or not grad_output.is_cuda:\n",
        "        raise ValueError(\"Tensors must be on CUDA\")\n",
        "\n",
        "    if not output.is_contiguous():\n",
        "        output = output.contiguous()\n",
        "    if not grad_output.is_contiguous():\n",
        "        grad_output = grad_output.contiguous()\n",
        "\n",
        "    grad_input = torch.empty_like(grad_output)\n",
        "\n",
        "    cuda_lib.launch_tanh_backward(\n",
        "        ctypes.c_void_p(output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_output.data_ptr()),\n",
        "        ctypes.c_void_p(grad_input.data_ptr()),\n",
        "        ctypes.c_int(output.numel())\n",
        "    )\n",
        "\n",
        "    return grad_input\n",
        "\n"
      ],
      "metadata": {
        "id": "xp1gxmKy6ixM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import EMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Custom autograd Functions - calling CUDA kernels.\n",
        "\n",
        "class DoubleFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = input.clone()\n",
        "        double_elements(output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = double_elements_backward(grad_output)\n",
        "        return grad_input\n",
        "\n",
        "class CustomDoubleLayer(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return DoubleFunction.apply(input)\n",
        "\n",
        "class CustomConvTranspose2dFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, stride, padding):\n",
        "        ctx.stride = stride\n",
        "        ctx.padding = padding\n",
        "        ctx.save_for_backward(input, weight)\n",
        "        output = conv_transpose_general_forward(input, weight, stride, padding)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weight = ctx.saved_tensors\n",
        "        d_input, d_weight = conv_transpose2d_backward(grad_output, input, weight, ctx.stride, ctx.padding)\n",
        "        return d_input, d_weight, None, None\n",
        "\n",
        "class CustomConvTranspose2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
        "        self.weight = nn.Parameter(torch.randn(in_channels, out_channels, *self.kernel_size))\n",
        "        nn.init.normal_(self.weight, 0.0, 0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return CustomConvTranspose2dFunction.apply(x, self.weight, self.stride, self.padding)\n",
        "\n",
        "class CustomBatchNorm2dFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, gamma, beta, eps):\n",
        "        ctx.eps = eps\n",
        "        N, C, H, W = input.shape\n",
        "        ctx.save_for_backward(input, gamma, beta)\n",
        "\n",
        "        mean = input.mean(dim=(0, 2, 3), keepdim=True)\n",
        "        var = input.var(dim=(0, 2, 3), keepdim=True, unbiased=False)\n",
        "\n",
        "        output = batchnorm_forward(input, gamma, beta, eps, N, C, H, W)\n",
        "\n",
        "        ctx.save_for_backward(input, mean, var, gamma)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, mean, var, gamma = ctx.saved_tensors\n",
        "        d_input, d_gamma, d_beta = batchnorm2d_backward(grad_output, input, mean, var, gamma, ctx.eps)\n",
        "        return d_input, d_gamma, d_beta, None\n",
        "\n",
        "\n",
        "class CustomBatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-5):\n",
        "        super(CustomBatchNorm2d, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return CustomBatchNorm2dFunction.apply(input, self.gamma, self.beta, self.eps)\n",
        "\n",
        "class CustomConv2dFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, stride, padding):\n",
        "        ctx.stride = stride\n",
        "        ctx.padding = padding\n",
        "        ctx.save_for_backward(input, weight)\n",
        "        output = conv2d_forward(input, weight, stride, padding)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weight = ctx.saved_tensors\n",
        "        d_input, d_weight = conv2d_backward(grad_output, input, weight, ctx.stride, ctx.padding)\n",
        "        return d_input, d_weight, None, None\n",
        "\n",
        "\n",
        "class CustomConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
        "        super(CustomConv2d, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
        "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, *self.kernel_size))\n",
        "        nn.init.normal_(self.weight, 0.0, 0.02)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = CustomConv2dFunction.apply(x, self.weight, self.stride, self.padding)\n",
        "        return output\n",
        "\n",
        "class CustomReLUFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = relu_forward(input)\n",
        "        ctx.save_for_backward(input)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = relu_backward(input, grad_output)\n",
        "        return grad_input\n",
        "\n",
        "class CustomReLUModule(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return CustomReLUFunction.apply(input)\n",
        "\n",
        "class CustomLeakyReLUFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, alpha=0.01):\n",
        "        output = leaky_relu_forward(input, alpha)\n",
        "        ctx.save_for_backward(input)\n",
        "        ctx.alpha = alpha\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = leaky_relu_backward(input, grad_output, ctx.alpha)\n",
        "        return grad_input, None\n",
        "\n",
        "class CustomLeakyReLUModule(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.01):\n",
        "        super(CustomLeakyReLUModule, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, input):\n",
        "        return CustomLeakyReLUFunction.apply(input, self.alpha)\n",
        "\n",
        "# Future Work\n",
        "class CustomSigmoidFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = sigmoid_forward(input)\n",
        "        ctx.save_for_backward(output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output, = ctx.saved_tensors\n",
        "        grad_input = sigmoid_backward(output, grad_output)\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "class CustomSigmoidModule(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return CustomSigmoidFunction.apply(input)\n",
        "\n",
        "# Future Work\n",
        "class CustomTanhFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = tanh_forward(input)\n",
        "        ctx.save_for_backward(output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output, = ctx.saved_tensors\n",
        "        grad_input = tanh_backward(output, grad_output)\n",
        "        return grad_input\n",
        "\n",
        "class CustomTanhModule(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return CustomTanhFunction.apply(input)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    np_img = img.numpy()\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGkW178X6q8W",
        "outputId": "e54b544d-8c9f-4e7f-bd37-6e10f9b6fea3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer1 = CustomConvTranspose2d(nz, ngf * 8, kernel_size=4, stride=1, padding=0)\n",
        "        self.layer2 = CustomConvTranspose2d(ngf * 8, ngf * 4, kernel_size=4, stride=2, padding=1)\n",
        "        self.layer3 = CustomConvTranspose2d(ngf * 4, ngf * 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.layer4 = CustomConvTranspose2d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1)\n",
        "        self.layer5 = CustomConvTranspose2d(ngf, nc, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        self.relu = CustomReLUModule()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.bn2 = CustomBatchNorm2d(ngf * 4)\n",
        "        self.bn3 = CustomBatchNorm2d(ngf * 2)\n",
        "        self.bn4 = CustomBatchNorm2d(ngf)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            CustomConv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            CustomLeakyReLUModule(0.2),\n",
        "            CustomConv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            CustomBatchNorm2d(ndf * 2),\n",
        "            CustomLeakyReLUModule(0.2),\n",
        "            CustomConv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            CustomBatchNorm2d(ndf * 4),\n",
        "            CustomLeakyReLUModule(0.2),\n",
        "            CustomConv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            CustomBatchNorm2d(ndf * 8),\n",
        "            CustomLeakyReLUModule(0.2),\n",
        "            CustomConv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1)"
      ],
      "metadata": {
        "id": "F-jjfUrU2O-0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "\n",
        "# Hyper-params\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "nc = 3  # RGB\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "dataset = datasets.CelebA(root=\"./data\", split=\"train\", download=True, transform=transform)\n",
        "indices = torch.arange(10000)\n",
        "dataset = Subset(dataset, indices)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# GPU Set up\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netD = Discriminator(nc, ndf).to(device)\n",
        "\n",
        "# Loss Function & Optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "print(\"Starting Training on GPU with Custom ConvTranspose Kernel...\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "        b_size = real_images.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        netD.zero_grad()\n",
        "        real_labels = torch.full((b_size,), 1, dtype=torch.float, device=device)\n",
        "        output_real = netD(real_images)\n",
        "        lossD_real = criterion(output_real, real_labels)\n",
        "        lossD_real.backward()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake_images = netG(noise)\n",
        "        fake_labels = torch.full((b_size,), 0, dtype=torch.float, device=device)\n",
        "        output_fake = netD(fake_images.detach())\n",
        "        lossD_fake = criterion(output_fake, fake_labels)\n",
        "        lossD_fake.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        # Train Generator\n",
        "        netG.zero_grad()\n",
        "        gen_labels = torch.full((b_size,), 1, dtype=torch.float, device=device)\n",
        "        output_gen = netD(fake_images)\n",
        "        lossG = criterion(output_gen, gen_labels)\n",
        "        lossG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"[{epoch+1}/{epochs}] [{i}/{len(dataloader)}] Loss_D: {(lossD_real+lossD_fake).item():.4f} | Loss_G: {lossG.item():.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training completed in {end_time - start_time:.2f} seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ckfch-9cqb",
        "outputId": "b81fced0-b2a8-46d7-9881-ed34d7f8114c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting Training on GPU with Custom ConvTranspose Kernel...\n",
            "\n",
            "[1/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[1/10] [50/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[1/10] [100/157] Loss_D: 1.5353 | Loss_G: 0.6931\n",
            "[1/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[2/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[2/10] [50/157] Loss_D: 1.0986 | Loss_G: 0.6931\n",
            "[2/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[2/10] [150/157] Loss_D: 1.1672 | Loss_G: 0.6931\n",
            "[3/10] [0/157] Loss_D: 1.0301 | Loss_G: 0.6931\n",
            "[3/10] [50/157] Loss_D: 1.3824 | Loss_G: 0.6931\n",
            "[3/10] [100/157] Loss_D: 1.7951 | Loss_G: 0.6931\n",
            "[3/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[4/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[4/10] [50/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[4/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[4/10] [150/157] Loss_D: 2.0064 | Loss_G: 0.6931\n",
            "[5/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[5/10] [50/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[5/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[5/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[6/10] [0/157] Loss_D: 1.0986 | Loss_G: 0.6931\n",
            "[6/10] [50/157] Loss_D: 1.4020 | Loss_G: 0.6931\n",
            "[6/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[6/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[7/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[7/10] [50/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[7/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[7/10] [150/157] Loss_D: 1.1672 | Loss_G: 0.6931\n",
            "[8/10] [0/157] Loss_D: 1.1026 | Loss_G: 0.6931\n",
            "[8/10] [50/157] Loss_D: 1.3960 | Loss_G: 0.6931\n",
            "[8/10] [100/157] Loss_D: 1.2303 | Loss_G: 0.6931\n",
            "[8/10] [150/157] Loss_D: 1.1227 | Loss_G: 0.6931\n",
            "[9/10] [0/157] Loss_D: 1.7918 | Loss_G: 0.6931\n",
            "[9/10] [50/157] Loss_D: 1.7951 | Loss_G: 0.6931\n",
            "[9/10] [100/157] Loss_D: 1.7918 | Loss_G: 0.6931\n",
            "[9/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[10/10] [0/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[10/10] [50/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[10/10] [100/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "[10/10] [150/157] Loss_D: 1.3863 | Loss_G: 0.6931\n",
            "Training completed in 113.70 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "fake_images = netG(noise).detach().cpu()\n",
        "\n",
        "generated_grid = torchvision.utils.make_grid(fake_images[:64], nrow=8, padding=2)\n",
        "imshow(generated_grid)\n"
      ],
      "metadata": {
        "id": "iD-WPmhO-vue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "47413e07-a20c-47f9-ed2d-a9f058eb68c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "print(\"\")\n",
        "N, C, H, W = 4, 3, 8, 8\n",
        "x = torch.randn(N, C, H, W, device=device, dtype=torch.float32)\n",
        "bn_native = nn.BatchNorm2d(C, eps=1e-5, affine=True).to(device)\n",
        "bn_native.train()\n",
        "bn_custom = CustomBatchNorm2d(C, eps=1e-5).to(device)\n",
        "bn_custom.train()\n",
        "bn_custom.gamma.data = bn_native.weight.data.clone()\n",
        "bn_custom.beta.data = bn_native.bias.data.clone()\n",
        "out_native = bn_native(x)\n",
        "out_custom = bn_custom(x)\n",
        "\n",
        "difference_norm = torch.norm(out_native - out_custom)\n",
        "\n",
        "print(\"Testing of PyTorch vs Custom Implementation of BatchNorm2d\")\n",
        "print(\"Difference norm between native and custom BN outputs:\", difference_norm.item())\n",
        "print(\"Native output (sample):\", out_native[0, 0, :2, :2])\n",
        "print(\"Custom output (sample):\", out_custom[0, 0, :2, :2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5ivH8x5a9Q",
        "outputId": "7920cc8f-0584-4967-8112-38d8c88dbe03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Testing of PyTorch vs Custom Implementation of BatchNorm2d\n",
            "Difference norm between native and custom BN outputs: 38.482818603515625\n",
            "Native output (sample): tensor([[-0.4162, -0.2167],\n",
            "        [-1.4618, -0.4961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "Custom output (sample): tensor([[1.0000e-08, 1.0000e-08],\n",
            "        [1.0000e-08, 1.0000e-08]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "print(\"\")\n",
        "\n",
        "# params\n",
        "batch = 2\n",
        "nz = 100\n",
        "out_channels = 512\n",
        "kernel_size = 4\n",
        "\n",
        "input_tensor = torch.randn(batch, nz, 1, 1, device=device, dtype=torch.float32)\n",
        "weight_tensor = torch.randn(nz, out_channels, kernel_size, kernel_size, device=device, dtype=torch.float32)\n",
        "custom_layer = CustomConvTranspose2d(nz, out_channels, kernel_size=kernel_size, stride=1, padding=0).to(device)\n",
        "custom_layer.weight.data = weight_tensor.clone()\n",
        "output_custom = custom_layer(input_tensor)\n",
        "conv_transpose = nn.ConvTranspose2d(nz, out_channels, kernel_size, stride=1, padding=0, bias=False).to(device)\n",
        "conv_transpose.weight.data = weight_tensor.clone()\n",
        "output_native = conv_transpose(input_tensor)\n",
        "\n",
        "difference_norm = torch.norm(output_custom - output_native)\n",
        "\n",
        "print(\"Testing of PyTorch vs Custom Implementation of ConvTranspose2d\")\n",
        "print(\"Difference norm between custom and native outputs:\", difference_norm.item())\n",
        "print(\"Custom output shape:\", output_custom.shape)\n",
        "print(\"Native output shape:\", output_native.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwqMkWE85fsf",
        "outputId": "df3a5b67-d90b-4d61-ce8e-7e0c5c1b8135"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Testing of PyTorch vs Custom Implementation of ConvTranspose2d\n",
            "Difference norm between custom and native outputs: 1244.0587158203125\n",
            "Custom output shape: torch.Size([2, 512, 4, 4])\n",
            "Native output shape: torch.Size([2, 512, 4, 4])\n"
          ]
        }
      ]
    }
  ]
}